[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "Might try blogging…\n\n\n\n\n\n\n\nannouncement\n\n\n\n\n\n\n\n\n\n\n\nOct 11, 2023\n\n\nCaleb Hallinan\n\n\n\n\n\n\n  \n\n\n\n\nSentiment and Topic Model Analysis of Alexandre Dumas & Others\n\n\n\n\n\n\n\n\n\n\n\n\nOct 5, 2023\n\n\nCaleb Hallinan\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "I am currently rotating in labs at JHU to determine what I’ll work on next!"
  },
  {
    "objectID": "projects.html#new-projects",
    "href": "projects.html#new-projects",
    "title": "Projects",
    "section": "",
    "text": "I am currently rotating in labs at JHU to determine what I’ll work on next!"
  },
  {
    "objectID": "projects.html#subtype-discovery-method-utilizing-scrna-seq-and-microarray-data",
    "href": "projects.html#subtype-discovery-method-utilizing-scrna-seq-and-microarray-data",
    "title": "Projects",
    "section": "subtype discovery method utilizing scRNA-seq and microarray data",
    "text": "subtype discovery method utilizing scRNA-seq and microarray data\n\nOur method, PHet, is able to distinguish multiple subtypes of data given only two labels (control and case)\n\n\n\n\nSummary of Abstract\nIn disease diagnosis and targeted therapy, discovering subtypes is crucial as cells or patients can exhibit varied responses to treatments. Hence, understanding the heterogeneity of disease states is vital for comprehending pathological processes. However, selecting features for subtyping from high-dimensional datasets is challenging, with many algorithms focusing on known disease phenotypes and potentially overlooking valuable subtyping information. Our study aimed to address this issue by identifying feature sets that preserve heterogeneity while discriminating known disease states. Through a data-driven approach combining feature clustering and deep metric learning, we developed a statistical method called PHet (Preserving Heterogeneity). This method effectively identifies a minimal set of features that maintain heterogeneity while maximizing the quality of subtype clustering. PHet outperformed previous methods in identifying disease subtypes using microarray and single-cell RNA-seq datasets. Our research provides an innovative feature selection method that facilitates personalized medicine and enhances understanding of disease heterogeneity. I am co-first author with my former labmate Dr. Abdurrahman Abul-Basher.\nCheck out the preprint here."
  },
  {
    "objectID": "projects.html#image-analysis-of-live-cell-imaging",
    "href": "projects.html#image-analysis-of-live-cell-imaging",
    "title": "Projects",
    "section": "image analysis of live-cell imaging",
    "text": "image analysis of live-cell imaging\nI worked under Dr. Kwonmoo Lee at Boston Children’s Hospital as a Research Assistant for two years after undergrad. My work included using various Convolutional Neural Networks (CNNs) for cell segmentation, utilizing cell tracking algorithms, honing my image manipulation skills (Fiji), working on my research writing aptitude, and much more! It was an incredible experience that has led me to where I am now :) Below are two papers I had the privilege of working on:\n\nThe Lee Lab developed a deep learning-based pipeline termed MARS-Net . While I did not contribute to it’s development, I helped the first author write the protocol for running it here.\nI helped in optimizing the hyper parameters for the R-CNN in FNA-Net, a deep-learning based ensemble model aimed to screen the adequacy of unstained thyroid fine needle aspirations (FNA). Ideally, this will streamline the diagnostic process by eliminating the need for staining and expert interpretation.\nMy biggest project was a subtype discovery method termed PHet. The abstract and preprint are above!"
  },
  {
    "objectID": "projects.html#github-contributions",
    "href": "projects.html#github-contributions",
    "title": "Projects",
    "section": "github contributions",
    "text": "github contributions"
  },
  {
    "objectID": "cv.html",
    "href": "cv.html",
    "title": "CV",
    "section": "",
    "text": "Here is my updated CV as of 10/11/2023"
  },
  {
    "objectID": "blog/2023-09-20-sentiment-analysis-example/index.html",
    "href": "blog/2023-09-20-sentiment-analysis-example/index.html",
    "title": "Sentiment and Topic Model Analysis of Alexandre Dumas & Others",
    "section": "",
    "text": "Code\n### install and read in packages\n\n# install.packages(\"wordcloud\") # install this for wordcloud\n# install.packages(\"janitor\") # install for sentiment analysis\n# install.packages(\"devtools\")\n# devtools::install_github(\"ropensci/gutenbergr\")\n# install.packages(\"tm\")\n\nlibrary(tidyverse) # for dataframes\nlibrary(devtools) # for classic functions\nlibrary(gutenbergr) # for data\nlibrary(here) # for use of others if downloaded\nlibrary(tidytext) # for sentiment analysis\nlibrary(paletteer) # for colors for plots\nlibrary(tm) # topic model package\nlibrary(topicmodels) # topic model package"
  },
  {
    "objectID": "blog/2023-09-20-sentiment-analysis-example/index.html#choosing-an-author",
    "href": "blog/2023-09-20-sentiment-analysis-example/index.html#choosing-an-author",
    "title": "Sentiment and Topic Model Analysis of Alexandre Dumas & Others",
    "section": "Choosing an Author",
    "text": "Choosing an Author\nInitially, the researcher expressed interest in exploring Charles Darwin’s works due to their background in Biology. However, after conducting a sentiment analysis on his works it became evident that they resembled scientific papers more so than books. As a result, the analysis on Darwin yielded less informative and exciting results than anticipated. Consequently, the focus shifted to the works of Alexandre Dumas, a celebrated fiction and fantasy novelist renowned for works such as The Three Musketeers and The Count of Monte Cristo - a classic the researcher has personally read and thoroughly enjoyed. From the extensive collection the gutenbergr package has to offer of Dumas’ books, six books were selected: The Three Musketeers, Ten Years Later, Twenty Years After, The Black Tulip, The Count of Monte Cristo, Illustrated, and the The Wolf-Leader. According to Alexandre Dumas’ Wikipedia page, his books are classified into various types of fiction. The first three books belong to The D’Artagnan Romances trilogy, while the The Count of Monte Cristo, Illustrated and The Black Tulip fall into the adventure genre. The Wolf-Leader was the final novel analyzed and was categorized as one of Dumas’ fantasy books. With this background knowledge, by performing a sentiment analysis we can not only uncover differences and similarities between individual books but also between different genres within Dumas’ literary repertoire.\n\n\nCode\n### Getting Dumas, Alexandre Data ###\n\n\n# if file doesn't exist, download the data\nif (!file.exists(here(\"dumas.RDS\"))) {\n  \n  # message it wasn't found\n  message(\"File not found, downloading now...\")\n  \n  dumas = gutenberg_works() |&gt;\n  # group by author\n  group_by(author) |&gt;\n  # filter to get dumas\n  filter(author == \"Dumas, Alexandre\") |&gt;\n  # download data\n  gutenberg_download(meta_fields = \"title\", strip=TRUE)\n  \n  # save the files to RDS objects\n  saveRDS(dumas, file = here(\"dumas.RDS\"))\n  \n  # message when done\n  message(\"Finished!\") \n}\n\n\n# read in dumas\ndumas = readRDS(here(\"dumas.RDS\"))\n# use git_ignore to not push\n# usethis::use_git_ignore(\"dumas.RDS\")\n\n\n# get row numbers for dumas\ndumas = dumas |&gt; \n  # get rid of id\n  select(-gutenberg_id) |&gt;\n  # get rid of lines with no text \n  filter(text != \"\") |&gt; \n  # group by title\n  group_by(title) |&gt;\n  # make new column\n  mutate(linenumber = row_number()) |&gt; \n  ungroup()"
  },
  {
    "objectID": "blog/2023-09-20-sentiment-analysis-example/index.html#sentiment-analysis",
    "href": "blog/2023-09-20-sentiment-analysis-example/index.html#sentiment-analysis",
    "title": "Sentiment and Topic Model Analysis of Alexandre Dumas & Others",
    "section": "Sentiment Analysis",
    "text": "Sentiment Analysis\nAfter conducting sentiment analysis on five of Alexandre Dumas’ well-known books, some interesting trends regarding his overall writing style and book-specific style emerged. Dumas’ writing exhibited a predominantly negative tone throughout, as evident by the cumulative sentiment declining constantly across all books. While this is only a small sample of his literary works, this trend is believed to be true based on our existing knowledge about Dumas.\n\n\nCode\n### Sentiment Analysis of Dumas, Alexandre Data ###\n\n# sample data here to save computational effort for rest of analysis\ndumas = dumas |&gt; \n  filter(title %in% c(\"The Three Musketeers\", \"Ten Years Later\", \"Twenty Years After\", \n                      \"The Black Tulip\", \"The Count of Monte Cristo, Illustrated\", \n                      \"The Wolf-Leader\"))\n\n\n# tokenize author\ntidy_dumas = dumas |&gt;\n  unnest_tokens(word, text)\n\n\n# # check to see what the top words are\n# tidy_dumas |&gt;\n#   # group by word\n#   group_by(word) |&gt;\n#   # count\n#   tally() |&gt; \n#   # arrange them\n#   arrange(desc(n)) \n# # NOTE: lots of the's and a's and such\n\n\n# # make a word cloud for just count of monte cristo\n# tt_dumas = tidy_dumas |&gt;\n#   # get count of monte\n#   filter(title == \"The Count of Monte Cristo, Illustrated\") |&gt;\n#   # get actual count of works\n#   count(word) |&gt;\n#   # arrange\n#   arrange(desc(n)) |&gt;\n#   # only get 200\n#   slice(1:200L)\n# # make a wordcloud of it\n# wordcloud::wordcloud(tt_dumas$word, tt_dumas$n)\n# # NOTE: lots of the's and a's and such\n\n\n# # can see words by by books\n# tidy_dumas |&gt;\n#   # count\n#   count(title, word) |&gt; \n#   #arrange\n#   arrange(desc(n)) |&gt; \n#   # group by title now\n#   group_by(title) |&gt; \n#   # get a couple\n#   slice(1L) \n\n\n# filter author with stop words\ntidy_dumas = tidy_dumas |&gt; \n  # get rid of stop words\n  anti_join(stop_words, by = \"word\")\n\n\n# # check with filtered author now\n# tidy_dumas |&gt;\n#   count(word) |&gt;\n#   arrange(desc(n))\n# # NOTE: lots of de, madame, replied, etc. that I should prob get rid of\n\n\n# top words by book\ntop_dumas_words = tidy_dumas |&gt;\n  # count with word and group by title\n  count(word, title) |&gt;\n  # arrange\n  arrange(desc(n)) |&gt; \n  # group by title\n  group_by(title) \n# top_dumas_words |&gt; slice(1:2)\n# NOTE: lots of names I should get rid of\n\n\n# # word cloud with no stop words\n# tt_dumas = tidy_dumas |&gt;\n#   # get count of monte again\n#   filter(title == \"The Count of Monte Cristo, Illustrated\") |&gt; \n#   # count\n#   count(word) |&gt;\n#   # arrange\n#   arrange(desc(n)) |&gt; \n#   # get 200\n#   slice(1:200L) \n# # make wordcloud\n# wordcloud::wordcloud(tt_dumas$word, tt_dumas$n)\n# # NOTE: \"count\" is highest word unsurpisingly\n\n\n# get bing sentiments\nbing = tidytext::sentiments \n# getting dupe words from janitor package\ndupes = bing |&gt; \n  janitor::get_dupes(word) \n# get rid of dupes\nbing = bing |&gt; \n  anti_join(dupes |&gt; filter(sentiment == \"positive\"))\n# check\n# anyDuplicated(bing$word) == 0\n# NOTE: good here!\n\n\n# top word sentiments with all words\n# top_dumas_words |&gt;\n#   slice(1:2) |&gt;\n#   left_join(bing, by = join_by(word))\n\n\n# # top word sentiments with only words with sentiment\n# top_dumas_words |&gt;\n#   # get rid of drop words\n#   filter(!word %in% dropwords) |&gt; \n#   inner_join(bing, by = join_by(word)) |&gt;\n#   slice(20:30) \n#   # NOTE: checked slices 1:30\n\n\n# Using this method to look at the text to determine if I should remove the word or not\n# or us a regex method\n# dumas |&gt;\n#   filter(str_detect(text, \"ah\"))\n\n# NOTES:\n# majesty: is usually \"his majesty\" or \"your majesty\" so remove all\n# honor: thought it would be like \"your honor\" but not really so keep it\n# prisoner: almost always its \"the prisoner\" so remove\n# master: mostly his master and master (referring to person), so add\n# excellency: same as your honor vibe, remove\n# stranger: not really used as person as much as I would have thought, so keep\n# de: found this when doing comparison to other others, just a name between names\n\n\n# going to get rid of some words here\ndropwords = c(\"majesty\", \"prisoner\", \"master\", \"excellency\", \"de\")\n\n\n# author sentiment\ndumassentiment = tidy_dumas |&gt; \n  # get rid of drop words\n  filter(!word %in% dropwords) |&gt; \n  # join with bing to get sentiment\n  inner_join(bing, by = join_by(word)) |&gt; \n  # TODO: what is this 80 for?\n  count(title, page = linenumber %/% 80, sentiment) |&gt; \n  # pivot wider data here\n  pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) |&gt; \n  # get sentiment score\n  mutate(sentiment = positive - negative) \n# check head of data\n# head(dumassentiment)\n# NOTE: looks good!\n\n\n# begin graphing\n\n\n# define the desired order of the legend\ndesired_order &lt;- c(\"The Three Musketeers\", \"Ten Years Later\", \"Twenty Years After\", \"The Black Tulip\", \n                   \"The Count of Monte Cristo, Illustrated\", \"The Wolf-Leader\")\n# define the desired colors for each title\ndesired_colors &lt;- c(\"darkblue\", \"blue\", \"lightblue\", \"darkred\", \"red\",\"darkgreen\")\n\n\n# change order for graph\ndumassentiment$title = factor(dumassentiment$title, levels = desired_order)\n\n\n\n\n# # ggplot of basic analysis of sentiment overtime\n# ggplot(dumassentiment, aes(page, sentiment, fill = title)) + \n#   # make bar graph, remove legend cause dont need\n#   geom_bar(stat = \"identity\", show.legend = FALSE) + \n#   # plot by book/title\n#   facet_wrap(~title, ncol = 3, scales = \"free_x\") +\n#   labs(\n#     x = \"Page Number\",\n#     y = \"Sentiment Score\",\n#     title = \"Sentiment Score Throughout Each Book\",\n#     caption = \"Data Source: Project Gutenberg\"\n#   ) + \n#   theme_bw() +\n#   theme(\n#     text = element_text(size = 11.5),\n#     plot.title = element_text(face = \"bold\", hjust = 0.5),\n#     legend.text = element_text(face = \"italic\")\n#     ) + \n#     scale_fill_manual(\n#     values = setNames(desired_colors, desired_order),\n#     breaks = desired_order\n#   )\n\n\n# plot the data\ng = dumassentiment|&gt; \n  # group by title\n  group_by(title) |&gt; \n  # get cumulative sentiment over time\n  mutate(sentiment = cumsum(sentiment), page = page/max(page)) |&gt; \n  # plot sentiment over time\n  ggplot(aes(page, sentiment, colour = title)) + \n  # make the line width bigger\n  geom_line(linewidth = 1.25) + \n  # labels\n  labs(\n    x = \"Percent of Total Pages (%)\",\n    y = \"Cumulative Sentiment\",\n    title = \"Trajectory of Sentiment Throughout Dumas' Works\",\n    caption = \"Data Source: Project Gutenberg\"\n  )\n\n# making transparent legend\ntransparent_legend = theme(legend.background = element_rect(fill = \"transparent\"), legend.key = \n                             element_rect(fill = \"transparent\", color = \"transparent\"))\n\n# plot\ng + \n  # add transparent legend\n  transparent_legend + \n  # change colors\n  # scale_color_brewer(type = \"qual\") + \n  # scale_colour_manual(values = paletteer_d(\"ggprism::colors\", 12), breaks = desired_order) +\n  # make specific colors go to specific titles\n  scale_colour_manual(\n    values = setNames(desired_colors, desired_order),\n    breaks = desired_order\n  ) +\n  # change x axis to percent\n  scale_x_continuous(labels = scales::percent_format()) + \n  # change theme to classic\n  theme_classic() + \n  # edit text\n  theme(\n    legend.position = c(0.25, 0.3), \n    text = element_text(size = 12),\n    plot.title = element_text(face = \"bold\", hjust = 0.5),\n    legend.text = element_text(face = \"italic\")\n    ) + \n  # change legend postion\n  guides(colour = guide_legend(title = \"Book\", override.aes = list(linewidth = 2)))\n\n\n\n\n\nWithin Dumas’ D’Artagnan Romances trilogy, represented by three shades of blue, The Three Musketeers had the lowest cumulative sentiment by the end of the book. The second book, Ten Years Later, contained a relatively more positive sentiment but remained negative overall. The final installment, Twenty Years After, displayed a negative cumulative sentiment similar to the first book. Hence, it appears that Dumas took readers on an emotional roller coaster from book to book while maintaining a generally negative connotation.\nAs for Dumas’ adventure genre books, The Count of Monte Cristo, Illustrated and The Black Tulip which are represented by shades of red, demonstrated significantly different sentiments over time. The Count of Monte Cristo, Illustrated had the lowest cumulative sentiment among all the books, while The Black Tulip approached a neutral sentiment by the end. Notably, The Count of Monte Cristo, Illustrated experienced a substantial drop in negative sentiment halfway through the book and continued its steep downward trend. Although the ending was not particularly positive, the researcher found the late and steep decline in negativity surprising given the “positive” elements (no spoilers) that are conveyed during that period if the book.\nLastly, a cumulative sentiment was performed on The Wolf-Leader, one of Dumas’ fantasy books. Despite its themes of werewolves, greed, power, and lust, the book had a slightly negative cumulative sentiment with minimal variation over time. Overall, it was somewhat surprising that the overall negative sentiment in this novel was not more pronounced.\nIt is important to note that certain words such as “majesty,” “prisoner,” “master,” and “excellency” were omitted from the analysis. These words were typically used as titles or names (e.g., “the prisoner” or “your excellency”) and did not significantly contribute to the books’ content. However, the exclusion of these words and the comparison between analyses with and without them did not lead to a significant deviation in the overall sentiment trend presented."
  },
  {
    "objectID": "blog/2023-09-20-sentiment-analysis-example/index.html#topic-model-analysis",
    "href": "blog/2023-09-20-sentiment-analysis-example/index.html#topic-model-analysis",
    "title": "Sentiment and Topic Model Analysis of Alexandre Dumas & Others",
    "section": "Topic Model Analysis",
    "text": "Topic Model Analysis\nNext, a topic model analysis using Latent Dirichlet allocation (LDA) was conducted. The Dumas’ dataset was combined with two new authors, Aristotle and Scott F. Fitzgerald, each contributing five distinct works. Aristotle’s selected books were The Poetics of Aristotle, The Categories, Politics: A Treatise on Government, Aristotle on the art of poetry, The Athenian Constitution. Scott F. Fitzgerald’s chosen works included This Side of Paradise, Flappers and Philosophers, The Beautiful and Damned, The Great Gatsby, All the Sad Young Men.\n\n\n\nCode\n### Getting Aristotle and Fitgerald Data ###\n\n\n# if file doesn't exist, download the data\nif (!file.exists(here(\"aristotle.RDS\"))) {\n  \n  # message it wasn't found\n  message(\"File not found, downloading now...\")\n  \n  aristotle = gutenberg_works() |&gt;\n  # group by author\n  group_by(author) |&gt;\n  # filter to get aristotle\n  filter(author == \"Aristotle\") |&gt;\n  # download data\n  gutenberg_download(meta_fields = \"title\", strip=TRUE)\n  \n  # save the files to RDS objects\n  saveRDS(aristotle, file = here(\"aristotle.RDS\"))\n  \n  # message when done\n  message(\"Finished!\") \n}\n\n\n# read in aristotle\naristotle = readRDS(here(\"aristotle.RDS\"))\n# use git_ignore to not push\n# usethis::use_git_ignore(\"aristotle.RDS\")\n\n\n# get row numbers for dumas\naristotle = aristotle |&gt; \n  # get rid of id\n  select(-gutenberg_id) |&gt;\n  # get rid of lines with no text \n  filter(text != \"\") |&gt; \n  # group by title\n  group_by(title) |&gt;\n  # make new column\n  mutate(linenumber = row_number()) |&gt; \n  ungroup()\n\n\n################################################\n\n\n# if file doesn't exist, download the data\nif (!file.exists(here(\"fitzgerald.RDS\"))) {\n  \n  # message it wasn't found\n  message(\"File not found, downloading now...\")\n  \n  fitzgerald = gutenberg_works() |&gt;\n  # group by author\n  group_by(author) |&gt;\n  # filter to get author\n  filter(author == \"Fitzgerald, F. Scott (Francis Scott)\") |&gt;\n  # download data\n  gutenberg_download(meta_fields = \"title\", strip=TRUE)\n  \n  # save the files to RDS objects\n  saveRDS(fitzgerald, file = here(\"fitzgerald.RDS\"))\n  \n  # message when done\n  message(\"Finished!\") \n}\n\n\n# read in aristotle\nfitzgerald = readRDS(here(\"fitzgerald.RDS\"))\n# use git_ignore to not push\nusethis::use_git_ignore(\"fitzgerald.RDS\")\n\n\n# get row numbers for dumas\nfitzgerald = fitzgerald |&gt; \n  # get rid of id\n  select(-gutenberg_id) |&gt;\n  # get rid of lines with no text \n  filter(text != \"\") |&gt; \n  # group by title\n  group_by(title) |&gt;\n  # make new column\n  mutate(linenumber = row_number()) |&gt; \n  ungroup()\n\n\n### Clean aristotle and fitzgerald Data, also do sentiment analysis but don't print ###\n\n\n# tokenize author\ntidy_aristotle = aristotle |&gt;\n  unnest_tokens(word, text)\n\n\n# filter author with stop words\ntidy_aristotle = tidy_aristotle |&gt; \n  # get rid of stop words\n  anti_join(stop_words, by = \"word\")\n\n\n# top words by book\ntop_aristotle_words = tidy_aristotle |&gt;\n  # count with word and group by title\n  count(word, title) |&gt;\n  # arrange\n  arrange(desc(n)) |&gt; \n  # group by title\n  group_by(title) \n# top_dumas_words |&gt; slice(1:2)\n\n\n# get bing sentiments\nbing = tidytext::sentiments \n# getting dupe words from janitor package\ndupes = bing |&gt; \n  janitor::get_dupes(word) \n# get rid of dupes\nbing = bing |&gt; \n  anti_join(dupes |&gt; filter(sentiment == \"positive\"))\n# check\n# anyDuplicated(bing$word) == 0\n# NOTE: good here!\n\n\n# # # top word sentiments with only words with sentiment\n# top_aristotle_words |&gt;\n#   # get rid of drop words\n#   filter(!word %in% dropwords) |&gt;\n#   inner_join(bing, by = join_by(word)) |&gt;\n#   slice(1:30)\n#   # NOTE: checked slices 1:30\n\n\n# Using this method to look at the text to determine if I should remove the word or not\n# or us a regex method\n# aristotle |&gt;\n#   filter(str_detect(text, \"cried\"))\n\n# NOTES:\n# majesty: is usually \"his majesty\" or \"your majesty\" so remove all\n# honor: thought it would be like \"your honor\" but not really so keep it\n# prisoner: almost always its \"the prisoner\" so remove\n# master: mostly his master and master (referring to person), so add\n# excellency: same as your honor vibe, remove\n# stranger: not really used as person as much as I would have thought, so keep\n\n\n# going to get rid of some words here\n# dropwords = c(\"majesty\", \"prisoner\", \"master\", \"excellency\")\n\n\n# # author sentiment\n# aristotlesentiment = tidy_aristotle |&gt; \n#   # get rid of drop words\n#   # filter(!word %in% dropwords) |&gt; \n#   # join with bing to get sentiment\n#   inner_join(bing, by = join_by(word)) |&gt; \n#   # TODO: what is this 80 for?\n#   count(title, page = linenumber %/% 80, sentiment) |&gt; \n#   # pivot wider data here\n#   pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) |&gt; \n#   # get sentiment score\n#   mutate(sentiment = positive - negative) \n# # check head of data\n# head(aristotlesentiment)\n# # NOTE: looks good!\n\n\n# # ggplot of basic analysis of sentiment overtime\n# ggplot(aristotlesentiment, aes(page, sentiment, fill = title)) + \n#   # make bar graph, remove legend cause dont need\n#   geom_bar(stat = \"identity\", show.legend = FALSE) + \n#   # plot by book/title\n#   facet_wrap(~title, ncol = 3, scales = \"free_x\") \n# \n# \n# # plot the data\n# g = aristotlesentiment|&gt; \n#   # group by title\n#   group_by(title) |&gt; \n#   # get cumulative sentiment over time\n#   mutate(sentiment = cumsum(sentiment), page = page/max(page)) |&gt; \n#   # plot sentiment over time\n#   ggplot(aes(page, sentiment, colour = title)) + \n#   # make the line width bigger\n#   geom_line(linewidth = 1.25) + \n#   # labels\n#   labs(\n#     x = \"Percent of Total Pages (%)\",\n#     y = \"Cumulative Sentiment\",\n#     title = \"Trajectory of Sentiment Throughout Aristotle's books\",\n#     caption = \"Data Source: Project Gutenberg\"\n#   )\n# \n# # making transparent legend\n# transparent_legend = theme(legend.background = element_rect(fill = \"transparent\"), legend.key = \n#                              element_rect(fill = \"transparent\", color = \"transparent\"))\n# \n# # plot\n# g + \n#   # add transparent legend\n#   transparent_legend + \n#   # change colors\n#   scale_color_brewer(type = \"qual\") +\n#   # scale_colour_manual(values = paletteer_d(\"ggprism::colors\", 12), breaks = desired_order) +\n#   # make specific colors go to specific titles\n#   # scale_colour_manual(\n#   #   values = setNames(desired_colors, desired_order),\n#   #   breaks = desired_order\n#   # ) +\n#   # change x axis to percent\n#   scale_x_continuous(labels = scales::percent_format()) + \n#   # change theme to classic\n#   theme_classic() + \n#   # edit text\n#   theme(\n#     legend.position = c(0.2, 0.75), \n#     text = element_text(size = 12),\n#     plot.title = element_text(face = \"bold\", hjust = 0.5),\n#     legend.text = element_text(face = \"italic\")\n#     ) + \n#   # change legend postion\n#   guides(colour = guide_legend(title = \"Book\", override.aes = list(linewidth = 2)))\n\n\n\n\n### Clean fitzgerald Data, also do sentiment analysis but don't print ###\n\n\n\n# tokenize author\ntidy_fitzgerald = fitzgerald |&gt;\n  unnest_tokens(word, text)\n\n\n# filter author with stop words\ntidy_fitzgerald = tidy_fitzgerald |&gt; \n  # get rid of stop words\n  anti_join(stop_words, by = \"word\")\n\n\n# top words by book\ntop_fitzgerald_words = tidy_fitzgerald |&gt;\n  # count with word and group by title\n  count(word, title) |&gt;\n  # arrange\n  arrange(desc(n)) |&gt; \n  # group by title\n  group_by(title) \n# top_fitzgerald_words |&gt; slice(1:2)\n\n\n# # # top word sentiments with only words with sentiment\n# top_fitzgerald_words |&gt;\n#   # get rid of drop words\n#   filter(!word %in% dropwords) |&gt;\n#   inner_join(bing, by = join_by(word)) |&gt;\n#   slice(1:30)\n#   # NOTE: checked slices 1:30\n\n\n# Using this method to look at the text to determine if I should remove the word or not\n# or us a regex method\n# fitzgerald |&gt;\n#   filter(str_detect(text, \"gentlemen\"))\n\n\n# going to get rid of some words here\n# dropwords = c(\"majesty\", \"prisoner\", \"master\", \"excellency\")\n\n\n# # author sentiment\n# fitzgeraldsentiment = tidy_fitzgerald |&gt; \n#   # get rid of drop words\n#   # filter(!word %in% dropwords) |&gt; \n#   # join with bing to get sentiment\n#   inner_join(bing, by = join_by(word)) |&gt; \n#   # TODO: what is this 80 for?\n#   count(title, page = linenumber %/% 80, sentiment) |&gt; \n#   # pivot wider data here\n#   pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) |&gt; \n#   # get sentiment score\n#   mutate(sentiment = positive - negative) \n# # check head of data\n# head(fitzgeraldsentiment)\n# # NOTE: looks good!\n# \n# \n# # ggplot of basic analysis of sentiment overtime\n# ggplot(fitzgeraldsentiment, aes(page, sentiment, fill = title)) + \n#   # make bar graph, remove legend cause dont need\n#   geom_bar(stat = \"identity\", show.legend = FALSE) + \n#   # plot by book/title\n#   facet_wrap(~title, ncol = 3, scales = \"free_x\") \n# \n# \n# # plot the data\n# g = fitzgeraldsentiment|&gt; \n#   # group by title\n#   group_by(title) |&gt; \n#   # get cumulative sentiment over time\n#   mutate(sentiment = cumsum(sentiment), page = page/max(page)) |&gt; \n#   # plot sentiment over time\n#   ggplot(aes(page, sentiment, colour = title)) + \n#   # make the line width bigger\n#   geom_line(linewidth = 1.25) + \n#   # labels\n#   labs(\n#     x = \"Percent of Total Pages (%)\",\n#     y = \"Cumulative Sentiment\",\n#     title = \"Trajectory of Sentiment Throughout Fitzgerald's books\",\n#     caption = \"Data Source: Project Gutenberg\"\n#   )\n# \n# # making transparent legend\n# transparent_legend = theme(legend.background = element_rect(fill = \"transparent\"), legend.key = \n#                              element_rect(fill = \"transparent\", color = \"transparent\"))\n# \n# # plot\n# g + \n#   # add transparent legend\n#   transparent_legend + \n#   # change colors\n#   scale_color_brewer(type = \"qual\") +\n#   # scale_colour_manual(values = paletteer_d(\"ggprism::colors\", 12), breaks = desired_order) +\n#   # make specific colors go to specific titles\n#   # scale_colour_manual(\n#   #   values = setNames(desired_colors, desired_order),\n#   #   breaks = desired_order\n#   # ) +\n#   # change x axis to percent\n#   scale_x_continuous(labels = scales::percent_format()) + \n#   # change theme to classic\n#   theme_classic() + \n#   # edit text\n#   theme(\n#     legend.position = c(0.2, 0.25), \n#     text = element_text(size = 12),\n#     plot.title = element_text(face = \"bold\", hjust = 0.5),\n#     legend.text = element_text(face = \"italic\")\n#     ) + \n#   # change legend postion\n#   guides(colour = guide_legend(title = \"Book\", override.aes = list(linewidth = 2)))\n\n\nUltimately, the purpose of this analysis was to: 1. Differentiate between the three authors using relevant keywords when excluding names and proper nouns 2. Identify interesting patterns among authors and/or books.\nFor these reasons, certain words identified in earlier analyses were excluded from the current results presented. These excluded words included names within the books such as “anthony,” “gatsby,” or “dantès,” as well as common pronouns like “sir,” “madame,” and “dear.” Additionally, words such as “lord,” “queen,” and “monk” were removed because within the context of the data they typically functioned more as nouns referring to individuals.\nSee the “Code” section below for the full list of words excluded from the analysis.\n\n\nCode\n# Coming back and getting rid of words (mainly names)\nwords_i_dont_want = c(\"anthony\", \"gloria\", \"amory\", \"aramis\", \"porthos\",\"athos\",\"d’artagnan\",\"count\",\n                      \"de\", \"monte\",\"cristo\",\"villefort\",\"danglars\",\"madame\", \"morrel\", \"cornelius\", \"rosa\",\n                      \"monsieur\",\"dantès\", \"valentine\", \"franz\", \"sir\", \"friend\", \"albert\",\"girl\", \"king\",\n                      \"lord\",\"queen\",\"raoul\",\"mazarin\",\"father\", \"caderousse\", \"sire\", \"morcerf\",\"majesty\",\n                      \"milady\", \"friends\", \"cardinal\", \"loius\", \"monk\", \"colbert\", \"fouquet\", \"dear\",\"daisy\",\n                      \"tom\", \"gatsby\", \"grimaud\", \"planchet\", \"la\", \"tulip\", \"louis\", \"prince\", \"woman\",\n                      \"duke\", \"mordaunt\", \"paris\", \"gentlemen\", \"boxtel\", \"baerle\",\"rosalind\", \"gryphus\",\"maury\",\n                      \"charles\", \"le\", \"francs\", \"buckingham\",\"comte\", \"guiche\",\"edmond\", \"andrea\",\"noirtier\",\n                      \"malicorne\", \"poet\", \"ii\", \"baisemeaux\", \"montalais\", \"bonacieux\", \"chapter\",\"prisoner\")\n\n\nLDA was first performed with three topics, with results and thoughts below.\n\n\n\nCode\n### LDA Analysis of all Authors ###\n\n\n# Get bag of words\n# author 1 bow\ntidy_freq_dumas = tidy_dumas  |&gt; \n  dplyr::ungroup()  |&gt; \n  # count words\n  count(title, word, name = \"count\") |&gt; \n  # filter for numbers\n  filter(is.na(as.numeric(word))) |&gt; \n  # get rid of this novel\n  filter(title != \"The Wolf-Leader\") |&gt; \n  # retroactively get rid of these words\n  filter(!word %in% words_i_dont_want)\n\n\n# author 2 bow\ntidy_freq_aristotle = tidy_aristotle  |&gt; \n  dplyr::ungroup()  |&gt; \n  # count words\n  count(title, word, name = \"count\") |&gt; \n  # filter for numbers\n  filter(is.na(as.numeric(word))) |&gt; \n  # retroactively get rid of these words\n  filter(!word %in% words_i_dont_want)\n\n\n# author 1 bow\ntidy_freq_fitzgerald = tidy_fitzgerald  |&gt; \n  dplyr::ungroup()  |&gt; \n  # count words\n  count(title, word, name = \"count\") |&gt; \n  # filter for numbers\n  filter(is.na(as.numeric(word))) |&gt; \n  # retroactively get rid of these words\n  filter(!word %in% words_i_dont_want)\n\n\n# combine data\ndf_authors123 = rbind(tidy_freq_dumas, tidy_freq_aristotle, tidy_freq_fitzgerald) |&gt; \n  # get rid of stop words\n  anti_join(stop_words, by = \"word\") |&gt; \n  # arrange in descending order\n  arrange(desc(count))\n# head(df_authors123)\n\n\n# make Document Term Matrix\ndtm_author &lt;- df_authors123  |&gt; \n  cast_dtm(title, word, count)\n\n\n# Perform LDA on 3 topics\nlda_author &lt;- LDA(dtm_author, k = 3L, control = list(seed = 10))\n# lda_author\n\n\n# Look at words per topic\nbeta_author &lt;- tidy(lda_author, matrix = \"beta\")\n# beta_author\n\n\n# look at top terms\ntop_terms &lt;- beta_author  |&gt; \n  # group by topic\n  group_by(topic)  |&gt; \n  # show top 10\n  slice_max(beta, n = 15)  |&gt;  \n  ungroup()  |&gt; \n  # arrange by lowest beta\n  arrange(topic, -beta)\n# top_terms\n\n\n# plot top terms\ntop_terms |&gt; \n  # reorder terms based on beta and topic\n  mutate(term = reorder_within(term, beta, topic)) |&gt;\n  # change topic from numbers to legible lables\n  mutate(topic = case_when(topic == 1 ~ \"Topic 1\",\n                           topic == 2 ~ \"Topic 2\",\n                           topic == 3 ~ \"Topic 3\")) |&gt; \n  # begin plotting\n  ggplot(aes(beta, term, fill = factor(topic))) +\n  # columns, or bars for expressing data\n  geom_col(show.legend = FALSE) +\n  # wrao based on the topic\n  facet_wrap(~ topic, scales = \"free_y\", nrow=2, ncol=2) +\n  scale_y_reordered() +\n  # labels for plot\n  labs(\n    x = \"Word Probability Per Topic (\\u03B2)\",\n    y = \"Word\",\n    title = \"Probability of Top Words Per Topic From a 3-Topic LDA\",\n    caption = \"Data Source: Project Gutenberg\"\n  ) + \n  # change theme\n  theme_linedraw() +\n  # edit text and legend\n  theme(\n    text = element_text(size = 12),\n    plot.title = element_text(face = \"bold\", hjust = 0.5),\n    legend.text = element_text(face = \"italic\")\n    ) +  \n  # change colors of plot\n    scale_fill_manual(\n    values = setNames(c(\"darkred\", \"darkgreen\",\"darkblue\"), c(\"Topic 1\", \"Topic 2\", \"Topic 3\")))\n\n\n\n\n\nExpressed above are the top 15 words within each topic determined by a 3-Topic LDA. Note there are no names, pronouns, or other words we omitted from the analysis. Topic 1 appears to be influenced by Aristotle’s books, as it contains words like “government,” “power,” and “voice.” Topic 2, and to a lesser degree Topic 3, contain many words in the past tense such as “replied” or “cried.” This interesting find suggests that some authors may have a preference for using the past tense more frequently than others.\nThere are some overlaps of words between topics such as “eyes” or “time.” In future work, particularly when classifying books, it might be of interest to examine why these overlaps are present and omit them from the analysis. However, for the purpose of this study we interpret these overlaps as potential commonalities between authors’ works and possible differences in word usage given specific contexts. For instance, in Dumas’ The Black Tulip, example quotes such as ““Of a tumult?” replied Cornelius, fixing his eyes on his perplexed” and “John, with tears in his eyes, wiped off a drop of the noble blood” showcase Dumas’ use of the word “eye” to describe eye actions. Conversely, in Aristotle’s Politics: A Treatise on Government, examples like “can see better with two eyes, and hear better with two ears” and “see that absolute monarchs now furnish themselves with many eyes” demonstrate Aristotle’s usage of “eye” as a noun rather than describing its actions. Countless more examples can be found in the text of words such as this.\nIt is worth noting that a word like “replied” likely differs from the “eye” example, as it is predominantly used when a person is responding to someone else. This common term is used frequently in books, so it was certainly interesting to see how it varies across topic and books as shown in the figure above and below.\n\n\nCode\n### LDA Analysis of all Authors Gamma Plot ###\n\n# check doc in each topic\ngamma_author &lt;- tidy(lda_author, matrix = \"gamma\")\n# gamma_author\n\n\n# get titles for each other\na1_titles = unique(tidy_dumas$title)\na2_titles = unique(tidy_aristotle$title)\na3_titles = unique(tidy_fitzgerald$title)\n# order for plot\nplot_order = c(a1_titles, a2_titles, a3_titles)\n\n\n# plot!\ngamma_author  |&gt; \n  # make title as factor of document, get plot order correct\n  mutate(title = factor(document, levels = plot_order))  |&gt; \n  # make new column author to use for facet wrap for more legible plot\n  mutate(author =  case_when(title %in% a1_titles ~ \"Alexandre Dumas\",\n                             title %in% a2_titles ~ \"Aristotle\",\n                             title %in% a3_titles ~ \"Scott F. Fitzgerald\")) |&gt; \n  # begin plot\n  ggplot(aes(x = title, y = gamma, fill = factor(topic))) +\n  # facet wrao by author with same y\n  facet_wrap(~author, scales = \"free_x\") +\n  # barplots\n  geom_col(width = 0.8) +\n  # labels\n  labs(\n    x = \"Book\",\n    y = paste(\"Topic Probability Per Book (\\u03B3)\"),\n    title = \"Proportion of Topics Per Book From a 3-Topic LDA\",\n    caption = \"Data Source: Project Gutenberg\",\n    fill = \"Topic\"\n  ) +\n  # change theme\n  theme_linedraw() +\n  # edit text and legend\n  theme(axis.text.x = element_text(angle = 55, hjust = 1),\n        plot.title = element_text(face = \"bold\", hjust = 0.5),\n        # legend.position = c(0.25, 0.3), \n        text = element_text(size = 12)) + \n  # change colors of fill\n  scale_x_discrete(labels = function(y) str_wrap(y, width = 20), expand = c(0, 0)) +\n  scale_fill_manual(values = c(\"darkred\", \"darkgreen\",\"darkblue\")) +\n  # scale_fill_manual(values = paletteer_d(\"ggprism::colors\", 12)) +\n  # add some padding\n  coord_cartesian(xlim = c(0.5,  5 + 0.5), expand = FALSE)\n\n\n\n\n\nThe figure above expresses how each topic was represented in the various books and highlights some differences between the authors. After removing names and pronouns, we see that each topic does not correspond exclusively to each author. However, the figure does reveal some intriguing results. Fitzgerald’s books exclusively consist only of Topic 1, Dumas’ books heavily feature Topic 2, while Aristotle’s works are a mixture of both Topics 1 and 2. This suggests how Fitzgerald and Aristotle may have more similar writing styles, or at least use more words in common, compared to Dumas. It also suggests that Dumas and Fitzgerald have little similarities in their writing style and choice of words.\nInterestingly, Topic 3 resides almost only in Dumas’ The Count of Monte Cristo, Illustrated. The unique words of this topic, such as “return” and “heard,” differ entirely from the top 15 words of the other topics. This also suggests that words such as “door” and “house” are used more frequently in this specific book compared to others. Additionally, a bit of Topic 3 was located in three other books written by Dumas emphasizing some consistency within his writing.\nUpon further examination of the data, it was discovered that Aristotle never mentions the word “cried” in any of his five works analyzed. However, Topic 2, which has the term “cried” as its third highest coefficient, represents a majority of two of Aristotle’s books. This suggests that including more topics will likely enhance our understanding of the underlying connections of these authors and their works. For that reason, another LDA was conducted using five topics. Note that Topics 1-3 will not be identical to the previous analysis.\n\n\n\nCode\n### LDA with more than 3 topics ###\n\n\n# Perform LDA on 3 topics\nlda_author &lt;- LDA(dtm_author, k = 5L, control = list(seed = 10))\n# lda_author\n\n\n# Look at words per topic\nbeta_author &lt;- tidy(lda_author, matrix = \"beta\")\n# beta_author\n\n\n# look at top terms\ntop_terms &lt;- beta_author  |&gt; \n  # group by topic\n  group_by(topic)  |&gt; \n  # show top 10\n  slice_max(beta, n = 15)  |&gt;  \n  ungroup()  |&gt; \n  # arrange by lowest beta\n  arrange(topic, -beta)\n# top_terms\n\n\n\n# plot top terms\ntop_terms |&gt; \n  # reorder terms based on beta and topic\n  mutate(term = reorder_within(term, beta, topic)) |&gt;\n  # change topic from numbers to legible lables\n  mutate(topic = case_when(topic == 1 ~ \"Topic 1\",\n                           topic == 2 ~ \"Topic 2\",\n                           topic == 3 ~ \"Topic 3\",\n                           topic == 4 ~ \"Topic 4\",\n                           topic == 5 ~ \"Topic 5\")) |&gt; \n  # begin plotting\n  ggplot(aes(beta, term, fill = factor(topic))) +\n  # columns, or bars for expressing data\n  geom_col(show.legend = FALSE) +\n  # wrao based on the topic\n  facet_wrap(~ topic, scales = \"free_y\", nrow=2, ncol=3) +\n  scale_y_reordered() +\n  # labels for plot\n  labs(\n    x = \"Word Probability Per Topic (\\u03B2)\",\n    y = \"Word\",\n    title = \"Probability of Top Words Per Topic From a 5-Topic LDA\",\n    caption = \"Data Source: Project Gutenberg\"\n  ) + \n  # change theme\n  theme_linedraw() +\n  # edit text and legend\n  theme(\n    text = element_text(size = 12),\n    plot.title = element_text(face = \"bold\", hjust = 0.5),\n    legend.text = element_text(face = \"italic\"),\n    axis.text.x = element_text(size = 8)\n    ) +  \n  # change colors of plot\n    scale_fill_manual(\n    values = setNames(c(\"darkred\", \"darkgreen\",\"darkblue\", \"darkorange\", \"#4B0076\"), c(\"Topic 1\", \"Topic 2\", \"Topic 3\", \"Topic 4\", \"Topic 5\")))\n\n\n\n\n\nA total of five topics were chosen in attempt to understand the differences between authors and their respective books. The previous analysis, using three topics, had shown to encounter an issue where certain topic words did not align with the books they were associated with. Although topic values ranging from four to eight were explored, it was determined that five topics was the most interesting and worth investigating further.\nThe above figure showcases the top 15 words for each of the newly generated topics produced from the LDA analysis. Topic 1 displays a strong correlation with Aristotle’s works on politics and philosophy, evident through words such as “government,” “public,” and “law.” Topics 2 and 3 contain many similar words like “time” and “cried” which were predominately related to Dumas’ books in the previous analysis. Notably, Topic 2 introduces the word “whilst,” while Topic 3 introduces the word “honor” which serve as novel distinguishing terms for differentiating between authors. In Topic 4, the word “eyes” has the highest score along with words like “night” and “day” that seemed to be connected to Fitzgerald in the last analysis. This topic also introduced the words “suddenly” and “love.” Lastly, Topic 5 was nearly identical to Topic 3 in the previous analysis, which primarily consisted of Dumas’ The Count of Monte Cristo, Illustrated.\nTo reemphasize, although there are many word overlaps across topics they were retained in hope to better understand the interaction of words within each topic. One interesting word that may pique the readers’ curiosity is “ah,” which has been retained in the analysis. This word was exclusively found in the works of Alexandre Dumas, as shown in the figures above. It is written in the text as instances like ““Ah! ah!” within twelve hours, you say?” and ““Ah, ah!” said William to his dog, “it’s easy to see that she is a”” which are from The Black Tulip. The decision was made not to omit this word, as it was used more frequently during this time period and aids in distinguishing between authors.\n\n\nCode\n### LDA Analysis of all Authors Gamma Plot ###\n\n# check doc in each topic\ngamma_author &lt;- tidy(lda_author, matrix = \"gamma\")\n# gamma_author\n\n\n# plot!\ngamma_author  |&gt; \n  # make title as factor of document, get plot order correct\n  mutate(title = factor(document, levels = plot_order))  |&gt; \n  # make new column author to use for facet wrap for more legible plot\n  mutate(author =  case_when(title %in% a1_titles ~ \"Alexandre Dumas\",\n                             title %in% a2_titles ~ \"Aristotle\",\n                             title %in% a3_titles ~ \"Scott F. Fitzgerald\")) |&gt; \n  # begin plot\n  ggplot(aes(x = title, y = gamma, fill = factor(topic))) +\n  # facet wrao by author with same y\n  facet_wrap(~author, scales = \"free_x\") +\n  # barplots\n  geom_col(width = 0.8) +\n  # labels\n  labs(\n    x = \"Book\",\n    y = paste(\"Topic Probability Per Book (\\u03B3)\"),\n    title = \"Proportion of Topics Per Book From a 5-Topic LDA\",\n    caption = \"Data Source: Project Gutenberg\",\n    fill = \"Topic\"\n  ) +\n  # change theme\n  theme_linedraw() +\n  # edit text and legend\n  theme(axis.text.x = element_text(angle = 55, hjust = 1),\n        plot.title = element_text(face = \"bold\", hjust = 0.5),\n        # legend.position = c(0.25, 0.3), \n        text = element_text(size = 12)) + \n  # change colors of fill\n  scale_x_discrete(labels = function(y) str_wrap(y, width = 20), expand = c(0, 0)) +\n  scale_fill_manual(values = c(\"darkred\", \"darkgreen\",\"darkblue\", \"darkorange\", \"#4B0076\")) +\n  # scale_fill_manual(values = paletteer_d(\"ggprism::colors\", 12)) +\n  # add some padding\n  coord_cartesian(xlim = c(0.5,  5 + 0.5), expand = FALSE)\n\n\n\n\n\nThe final figure above illustrates the representation of each topic across the various books while highlighting certain differences among the authors. When the number of topics was increased from three to five there was a complete separation among all authors, with Dumas exhibiting subcategories within his books.\nUnsurprisingly, Aristotle was exclusively represented by Topic 1, which was not found in any other novel. This phenomena likely occured because of words within the top 15 of Topic 1 such as “government,” “democracy,” and “oligarchy,” which closely resemble the themes explored in Aristotle’s works on politics. It was fascinating that these words primarily relate to Aristotle’s Politics: A Treatise on Government and The Athenian Constitution rather than his poetic works of The Poetics of Aristotle and Aristotle on the art of poetry. Further exploration may involve identifying distinct keywords that better differentiate these bodies of work from one another.\nFitzgerald was represented solely by Topic 4 in this analysis, which was characterized by words such as “night,” “day,” “suddenly,” and “love.” Considering the selected works of this author, it comes as no surprise that these words achieve high scores for Fitzgerald. However, if words such as “woman,” “girl,” or “gentlemen,” which were excluded from the analysis, were included, the books would likely better differentiate into different topics.\nMost interestingly, despite being compared to Aristotle and Fitzgerald’s works, Dumas’ five works are divided into three topics. The Count of Monte Cristo, Illustrated forms its own distinctive topic, Topic 5, corresponding exactly to Topic 3 in the previous analysis. Topic 3 was mainly found in The Three Musketeers and Ten Years Later, while Topic 4 was predominately in The Black Tulip and Twenty Years After. It was expected that the D’Artagnan Romances trilogy would fall under a single topic, and while this was mostly the case, Twenty Years After contains a significant portion of Topic 2. Topic 2 was fully associated with The Black Tulip, an adventure novel by Dumas characterized with distinguishing words such as “whilst” and “van.” Overall, it was satisfying to observe that this analysis successfully achieves its objective of distinguishing between authors and their works, while also revealing aforementioned subcategories within Dumas’ books."
  },
  {
    "objectID": "blog/2023-09-20-sentiment-analysis-example/index.html#conclusion",
    "href": "blog/2023-09-20-sentiment-analysis-example/index.html#conclusion",
    "title": "Sentiment and Topic Model Analysis of Alexandre Dumas & Others",
    "section": "Conclusion",
    "text": "Conclusion\nIn conclusion, the authors’ works exhibit notable differences as revealed through this analysis. Specific words unique to each author were successfully identified, indicating distinct writing styles among Dumas, Aristotle, and Fitzgerald. Moreover, the analysis successfully distinguished all three authors and discovered the previously mentioned subcategories within Dumas’ works using a five-topic LDA model. Future research could focus on identifying distinguishing words between books authored by Aristotle and Fitzgerald."
  },
  {
    "objectID": "teaching.html",
    "href": "teaching.html",
    "title": "Teaching",
    "section": "",
    "text": "TBD"
  },
  {
    "objectID": "blog/might-try-blogging/index.html",
    "href": "blog/might-try-blogging/index.html",
    "title": "Might try blogging…",
    "section": "",
    "text": "I am thinking about blogging some things… not really specific topics or thoughts, just notes I want to jot down because why not."
  },
  {
    "objectID": "talks.html",
    "href": "talks.html",
    "title": "Talks/Posters",
    "section": "",
    "text": "2023\nPosters:\n\n“Phenotyping of Heterogenous Live Cell Motility and Morphology,” Dr. M. Judah Folkman Research Day, Boston Children’s Hospital & Harvard Medical School, Boston, MA, 2023.\n\n\n\n\n\n\n2022\nTalks:\n\n“Machine Learning Approaches Applied to the Prediction of Covid-19 Spread and Cell Motility Phenotyping,” Vascular Biology Program Work in Progress, Boston Children’s Hospital & Harvard Medical School, Boston, MA, 2022.\n\n\n\n\n\n\n“Deconvolution of Cellular Heterogeneity for Sub-Type Discovery by Analyzing Feature Variation,” Vascular Biology Program Work in Progress, Boston Children’s Hospital & Harvard Medical School, Boston, MA, 2022.\n\n\n\n\n\nPosters:\n\n“Deep-Hetero: A Deep Metric Learning with UMAP-based Clustering Approach for Identifying Heterogeneity in Cells,” Dr. M. Judah Folkman Research Day, Boston Children’s Hospital & Harvard Medical School, Boston, MA, 2022.\n\n\n\n2021\nPosters:\n\n“Ultrasound Microbubble Tumor Analysis,” Focused Ultrasound Foundation Summer Intern Presentations, Focused Ultrasound Foundation, Charlottesville, VA, 2021."
  },
  {
    "objectID": "software.html",
    "href": "software.html",
    "title": "Software and data packages",
    "section": "",
    "text": "TBD\n\n\n\nTBD"
  },
  {
    "objectID": "software.html#bioconductor",
    "href": "software.html#bioconductor",
    "title": "Software and data packages",
    "section": "",
    "text": "TBD\n\n\n\nTBD"
  },
  {
    "objectID": "software.html#cran",
    "href": "software.html#cran",
    "title": "Software and data packages",
    "section": "CRAN",
    "text": "CRAN\n\nSoftware packages\nTBD"
  },
  {
    "objectID": "software.html#python",
    "href": "software.html#python",
    "title": "Software and data packages",
    "section": "Python",
    "text": "Python\n\nSoftware packages\nTBD"
  },
  {
    "objectID": "software.html#github",
    "href": "software.html#github",
    "title": "Software and data packages",
    "section": "GitHub",
    "text": "GitHub\n\nSoftware packages\nTBD\n\n\nData packages\nTBD"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Caleb Hallinan",
    "section": "",
    "text": "First Year PhD Student in Biomedical Engineering at Johns Hopkins University \nMy proficiencies lie in the domains of data analysis, machine learning, and the development and implementation of high-end computational research tools. I hope to utilize these skills and more to analyze biomedical data :)\nIn my spare time I love to watch and play sports, hang out with friends, and run!\n\n\nJohns Hopkins University, Baltimore, MD\nPhD in Biomedical Engineering | Aug 2023 - TBD 2028\nUniversity of Virginia | Charlottesville, VA\nB.A. in Statistics and Biology | Aug 2017 - May 2021\n\n\n\nBoston Children’s Hospital | Boston, MA\nResearch Assistant | Sept 2021 - June 2023"
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Caleb Hallinan",
    "section": "",
    "text": "Johns Hopkins University, Baltimore, MD\nPhD in Biomedical Engineering | Aug 2023 - TBD 2028\nUniversity of Virginia | Charlottesville, VA\nB.A. in Statistics and Biology | Aug 2017 - May 2021"
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Caleb Hallinan",
    "section": "",
    "text": "Boston Children’s Hospital | Boston, MA\nResearch Assistant | Sept 2021 - June 2023"
  }
]