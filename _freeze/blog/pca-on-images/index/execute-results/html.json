{
  "hash": "fb1b3cc641c1e0425eba0334e83d3077",
  "result": {
    "markdown": "---\ntitle: \"Performing Principal Component Analysis on Flag Images in R\"\nauthor: \"Caleb Hallinan\"\ndate: 10/19/2023\nformat:\n  html:\n    code-fold: true\n    code-summary: \"Code\"\n    code-tools: true\n    embed-resources: true\nfontsize: 12pt\ngeometry: margin=1.5in\nfontcolor: white\n---\n\n\n<!-- Global params -->\n\n\n\n\n\n\n\nIn this project, we will embark on an adventure using Principal Component Analysis on images of various flags of countries/regions. Hopefully by the end you will have a better understanding of PCA and how we can utilize it to look at images in R!\n\nNote: I condensed the R code to \"Code\" sections throughout for scrolling purposes. Feel free to click on these sections to look at each step, or change to \"Show All Code\" in the top right of the webpage!\n\n\n\n## Introduction\n\nPrincipal Components Analysis (PCA) is a well-established technique to reduce the dimensions or features of a dataset while preserving the maximum amount of variation. This technique is widely used for pattern recognition, signal processing, and machine learning. PCA is also a useful tool in denoising, visualization, and classification of large datasets given features are linearly related. For example, imagine you have a genomics dataset with 10000+ genes and 5000+ observations. That's a lot of data! However, not all of those genes will be important as likely many of them are correlated, or express similar variation, as others. PCA is a great tool to reduce the 10000+ dimensions to a smaller number, eliminating redundancy by reducing the dimensions of the dataset for more downstream analysis.\n\n\n<!-- PCA image -->\n\n::: {style=\"text-align: center;\"}\n![[Image Source](https://medium.com/analytics-vidhya/dimensionality-reduction-principal-component-analysis-d1402b58feb1)](pca.gif){width=600}\n:::\n\n\nPCA is heavily based on linear algebra concepts. Essentially, PCA computes the eigenvectors of the covariance matrix of the data and sorts them by their eigenvalue (which correspond to the explained variance for that individual principal component). The principal components (PC) are then computed as linear combinations of the original variables using the eigenvectors. It sounds complicated, but I promise you it's not as hard to understand as you think. This\n[article](https://builtin.com/data-science/step-step-explanation-principal-component-analysis) was a great resource for me when I was first trying to figure it out. Unfortunately, I won't go into much of the algebra behind PCA, so I encourage you to research it more! You can see this really cool animation above expressing what PCA is doing in two dimensions. Briefly, it is finding the direction that maximizes the variance of the blue dots which can also be viewed as minimizing the residuals of the blue dots to a line.\n\n\n\n## Data\n\nIn this project specifically, instead of working with gene expressions or large datasets with numerous features, we are looking at images of flags from different countries. The goal is to apply PCA to these flags to assess its effectiveness in preserving variation and possibly discover interesting patterns or insights in the principal components themselves.\n\nTo begin our exploration, we need to install and load some R packages. These packages will equip us with the necessary tools for working with data frames, functions, file paths, reading images, and image processing.\n\n<!-- Install/Read packages -->\n\n\n::: {.cell}\n\n```{.r .cell-code}\n### install and read in packages\n\nlibrary(tidyverse) # for dataframes\nlibrary(here) # for use of others if downloaded\nlibrary(png) # for reading png images\nlibrary(magick) # for reading in images\nlibrary(imager) # for plotting\n```\n:::\n\n\n\n\nNow that we have the necessary packages, let's grab the flag data from [here](https://github.com/hampusborgos/country-flags). This dataset contains flags of varying sizes within different folders, however we are going to look specifically at the \"/png250px/\" folder. This folder has 255 flags from various countries and regions.\n\n<!-- Get the Data -->\n\n\n::: {.cell}\n\n```{.r .cell-code}\n### Grabbing the data\n\n# url to flag data, it is in zip file\nurl = \"https://github.com/hampusborgos/country-flags/archive/refs/heads/main.zip\"\n\n# specify the file name and location where you want to save the file on your computer\nfile_name = \"flags.zip\"\nfile_path = here()\n\n# use the download.file() function\ndownload.file(url, paste(file_path, file_name, sep = \"/\"), mode = \"wb\")\n\n# unzip zip file\nunzip(paste0(here(), \"/flags.zip\"), exdir = here())\n\n# get file names\nfiles = list.files(here(\"country-flags-main/png250px/\"), full.names = TRUE)\n\n# Read each image file in the folder\nimage_list = lapply(files, image_read)\n# image_list = lapply(files, readPNG)\n```\n:::\n\n\n\nFor PCA to work soundly, it is essential that the dataset's dimensions remain consistent. Of course, that's not the case in this dataset where we see all flags have the same height (250px) but very different widths. Hence, we need to resize each flag to be the same height and width. I use the magick R package to read in the images and the \"image_scale\" along with the \"image_convert\" functions to transform the images into size 250x250x3 (representing height, width, and color channel). These resized images are then saved in the folder \"/resized_png250px/.\" To enable PCA analysis, the images are converted from matrix to vector format. This involves flattening the 250x250x3 image matrix into a single vector of size 1x187500 (250 x 250 x 3). The individual vectors for each image are then combined into a single matrix of dimensions 255x187500. This variable, \"image_matrix\" is created and saved as flags_matrix.RDS. Also to note, this matrix is country/region flag image x pixel of flag image.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# NOTE: so each image is the same height but very different widths lol. Let's change that\n\n# Set height and width I want\nmax_height = 250\nmax_width = 250\n\n# Resize all the images to the specified height and width\n# had to add matte=FALSE to get rid of extra channel\nresized_images = lapply(image_list, function(im) {\n  image_convert(image_scale(im, paste0(max_width, \"x\", max_height, \"!\")), format = \"png\", matte=FALSE)\n})\n\n\n# Create the directory to save the resized images\ndir.create(\"resized_png250px\")\n\n# Save the resized images with the same names as the original files\nfor (i in seq_along(resized_images)) {\n  # Extract the file name from the full path\n  file_name = basename(files[i])\n  # make the file path for saving the resized image\n  save_path = file.path(\"resized_png250px\", file_name)\n  # Write the resized image to the specified file path\n  image_write(resized_images[[i]], save_path)\n}\n\n\n# now grab them with png package\nresized_files = list.files(here(\"blog/pca-on-images/resized_png250px\"), full.names = TRUE)\n\n# use function readPNG\nimgs_final = lapply(resized_files, readPNG)\n\n# QC: check each image is same dimensions\n# for (i in seq_along(imgs_final)) {\n#   dimensions = dim(imgs_final[[i]])\n#   cat(\"Image\", i, \"Dimensions:\", dimensions[1], \"x\", dimensions[2], \"x\", dimensions[3], \"\\n\")\n# }\n\n# great!\n\n# Get the number of images in the list\nnum_images = length(image_list)\n\n# Create an empty matrix to store the flattened images\nimage_matrix = matrix(NA, nrow = num_images, ncol = 250 * 250 * 3)\n\n# Flatten each image and store it as a column in the matrix\nfor (i in 1:num_images) {\n  # get the flatten vector\n  flattened_image = as.vector(imgs_final[[i]])\n  # add to matrix\n  image_matrix[i,] = flattened_image\n}\n\n# save as .rds file\nsaveRDS(image_matrix, file = here(\"flags_matrix.RDS\"))\n\n\n# plot images\n\n# want to add all images to this dataframe for ggplot\nall_images = data.frame()\n\n# for loop getting 5 examples\nfor (i in seq(1,190,20)) {\n  # getting image - making cimg from imager package and then df\n  img = as.data.frame(as.cimg(imgs_final[[i]]), wide = \"c\") |> \n    # # get rgb channels\n    mutate(rgb_value = rgb(c.1, c.2, c.3)) |>\n    # # make class labels\n    mutate(img_num = paste(\"Image\",i))\n  \n  all_images = rbind(all_images, img)\n  \n  # make the levels of img variable what i want\n  all_images$img_num = factor(all_images$img_num, levels = sprintf(\"Image %d\", seq(1, 190, 20)))\n\n}\n\n# plot image\nprint(ggplot(all_images,aes(y,x))+\n  # getting rgb\n  geom_raster(aes(fill=rgb_value))+\n  # fill image\n  scale_fill_identity() +\n  # facet_wrap\n  facet_wrap(.~ img_num, nrow = 2, ncol = 5) +\n  # reverse y axis\n  scale_y_reverse() + \n  # get rid of theme\n  theme_void() +\n  # bigger font size\n  theme(strip.text = element_text(size = 12)))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-1-1.png){fig-align='center' width=864}\n:::\n:::\n\n\nHere are ten examples of the flag image data we are using.\n\n\n\n## PCA on the training data\n\nTechnically our \"image_matrix\" variable could be input straight into PCA the way it is. However, we are going to split the 255 images into a training and test set. Why do we do this? Well, for one it was part of the project description ðŸ˜… But really we do this to see how well PCA will predict, or project, the test data using only information from the training data. Our training set we take to be 75% of the data (191 flags) leaving 25% of data being the test images (64 flags). Finally, we are ready to conduct PCA on the training data! Note that we are setting center=TRUE and scale.=False. Briefly, the center hyperparameter shifts the data to be zero centered (subtracting the mean from each column) while scale will make the data have unit variance (correlation instead of covariance PCA). Centering is crucial for PCA to perform correctly, however scaling is dataset dependent. Take a look at the [prcomp function description](https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/prcomp) for more information.\n\n<!-- PCA Analysis -->\n\n\n::: {.cell}\n\n```{.r .cell-code}\n### Do PCA analysis ###\n\n# Set the seed \nset.seed(123)\n\n# Get the number of images in the list - for some reason needed to add this to this code chunk\nnum_images = dim(image_matrix)[1]\n\n# Calculate the number of columns for training data\ntrain_columns = floor(0.75 * num_images)\n\n# Randomly select indices for the training data\ntrain_indices = sample(1:num_images, train_columns)\n\n# Get the test indices\ntest_indices = setdiff(1:num_images, train_indices)\n\n# Split the image matrix into training and test data\ntrain_data = image_matrix[train_indices, ]\ntest_data = image_matrix[-train_indices, ]\n\n# Perform PCA on the training data, centering data but NOT scaling\npca_result = prcomp(train_data, center=TRUE, scale. = FALSE)\n```\n:::\n\n\n\n\nLet's extract some key information form the prcomp function. We are able to calculate the proportion of variance explained from each PC by looking at the $sdev$ value, aka the standard deviations of the principal components, by squaring them and dividing by the sum of the squared $sdev$ values. To note, $sdev^2$ is actually equal to the eigenvalues of the dataset! We can then get the cumulative variation as the number of PC components increase, leading to the plot you see below. Here we see that as PCs increase so does the cumulative variance preserved/explained. This is an excellent visualization to check how much each PC contributes to preserving overall variation. In our case we see that with just 67 PCs we can explain 95% of the variation in the dataset! \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Extract the proportion of variance explained by each principal component\nvariance_explained = pca_result$sdev^2 / sum(pca_result$sdev^2)\n\n# Calculate the cumulative percentage of variance explained\ncumulative_variance = cumsum(variance_explained) * 100\n\n# get pcs getting more than 95% of the data\npcs_for_95 = which(cumsum(variance_explained) >= 0.95)[1]\n\n# Create a tibble for plotting\ndata_plot = tibble(\n  # x axis\n  num_components = 1:length(cumulative_variance),\n  # cumvar\n  cumulative_variance = cumulative_variance\n)\n\n# plot using ggplot2\nggplot(data_plot, aes(x = num_components, y = cumulative_variance)) +\n  # make line plot\n  geom_line() +\n  # add points\n  geom_point() +\n  # adding line for which PC number we are getting\n  geom_vline(xintercept = pcs_for_95, color = \"red\", linetype = \"dashed\") +\n  # adding text for PC im getting\n  annotate(\"text\", x = 70, y = 85, label = paste(\"95% variation explained\\nwith\", as.character(pcs_for_95), \"PCs\"), hjust = 0, vjust = 0, color = \"black\", size = 4) +\n  # x axis every 20\n  scale_x_continuous(breaks = seq(0, max(data_plot$num_components), by = 20)) +\n  # y axis every 20\n  scale_y_continuous(breaks = seq(0, 100, by = 20)) +\n  # labels\n  labs(x = \"Number of Principal Components\",\n       y = \"Cumulative Variance Explained (%)\",\n       title = \"Cumulative Variance Explained with Additional Principal Components\") +\n  # theme\n  theme_bw() +\n  # change text vars\n  theme(plot.title = element_text(hjust = 0.5, face = \"bold\"),\n        axis.text = element_text(size = 10))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nAnother popular plot used to visualize PCs and their explained variation is a scree plot. Check out the [wiki page](https://en.wikipedia.org/wiki/Scree_plot) for more information.\n\n\n\nSo we were able to successfully perform PCA on our image data... what now? Well, let's see how well we can reconstruct the data using only the first 67 PCs, which contained 95% of the variance. To achieve this, we need to do a bit of matrix multiplication as well as add the mean back to un-center the data. \n\nThe PCA reconstructed data = the PC scores (matrix dimensions 191x191) x the transpose of the eigenvectors (matrix dimensions 191x187500) + mean\n\nIf we wanted to take only the top k PCs, which in our case I wanted the top 67, then we simply subset the PC scores and eigenvectors from 191 to 67. I then reconstruct the image matrix from the single image vector, normalize the values from 0-1, and save all the newly reconstructed image matrices in a single list. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n### reconstructing training data ###\n\n# use pca_results to reconstruct training data fully\nreconstructed_train_data_allpcs = pca_result$x %*% t(pca_result$rotation)\n# scale data back to center\nreconstructed_train_data_allpcs = scale(reconstructed_train_data_allpcs, center = -pca_result$center, scale = FALSE)\n\n# now use just 95% variation explained pcs\nreconstructed_train_data_95 = pca_result$x[,1:pcs_for_95] %*% t(pca_result$rotation[,1:pcs_for_95])\n# scale data back to center\nreconstructed_train_data_95 = scale(reconstructed_train_data_95, center = -pca_result$center, scale = FALSE)\n\n# Create an empty list to store the 250x250x3 matrices\nmatrices_250x250x3 = vector(\"list\", length(length(train_indices)))\n\n# Generate a 250x250x3 matrix for each row in image_matrix\nfor (i in 1:length(train_indices)) {\n  # flattened_image = as.vector(imgs_final[[i]])\n  matrix_250x250x3 = array(reconstructed_train_data_allpcs[i,], dim = c(250, 250, 3))\n  matrices_250x250x3[[i]] = matrix_250x250x3\n}\n\n# Function to normalize the matrix \nnormalize_matrix = function(matrix) {\n  min_value = min(matrix)\n  max_value = max(matrix)\n  normalized_matrix = (matrix - min_value) / (max_value - min_value)\n  return(normalized_matrix)\n}\n\n# Normalize each matrix in the list\nflags_reconstructed_train_data_allpcs = lapply(matrices_250x250x3, normalize_matrix)\n\n# now do for 95% variation\n\n# Create an empty list to store the 250x250x3 matrices\nmatrices_250x250x3 = vector(\"list\", length(length(train_indices)))\n\n# Generate a 250x250x3 matrix for each row in image_matrix\nfor (i in 1:length(train_indices)) {\n  # flattened_image = as.vector(imgs_final[[i]])\n  matrix_250x250x3 = array(reconstructed_train_data_95[i,], dim = c(250, 250, 3))\n  matrices_250x250x3[[i]] = matrix_250x250x3\n}\n\n# Normalize each matrix in the list\nflags_reconstructed_train_data_95 = lapply(matrices_250x250x3, normalize_matrix)\n```\n:::\n\n\n\n\n\nNow let's view how well PCA reconstructed the data! I utilized ggplot to plot three versions of five different flags: the original resized training image, the reconstructed resized training image with all PCs, the reconstructed resized training image with 67 PCs.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# for loop getting 5 examples\nfor (i in 1:5) {\n  \n  # getting image - making cimg from imager package and then df\n  img1 = as.data.frame(as.cimg(imgs_final[[train_indices[i]]]), wide = \"c\")  |> \n    # get rgb channels\n    mutate(rgb_value = rgb(c.1, c.2, c.3)) |>\n    # make class for facet_wrap\n    mutate(image_type = \"Original Image\")\n  \n  # getting image - making cimg from imager package and then df\n  img2 = as.data.frame(as.cimg(flags_reconstructed_train_data_allpcs[[i]]), wide = \"c\") |>\n    # get rgb channels\n    mutate(rgb_value = rgb(c.1, c.2, c.3)) |>\n    # make class for facet_wrap\n    mutate(image_type = \"Fully Reconstructed Image\")\n\n  # getting image 1 - making cimg from imager package and then df\n  img3 = as.data.frame(as.cimg(flags_reconstructed_train_data_95[[i]]), wide = \"c\") |>\n    # get rgb channels\n    mutate(rgb_value = rgb(c.1, c.2, c.3)) |>\n    # make class for facet_wrap\n    mutate(image_type = \"67 PCs Reconstructed Image\")\n  \n  # combining to all images\n  all_images = rbind(img1, img2, img3)\n  \n  # make the levels of img variable what i want\n  all_images$image_type = factor(all_images$image_type, levels = c(\"Original Image\", \"Fully Reconstructed Image\",\"67 PCs Reconstructed Image\"))\n\n  # plot image\n  print(ggplot(all_images,aes(y,x))+\n    # getting rgb\n    geom_raster(aes(fill=rgb_value))+\n    # fill image\n    scale_fill_identity() +\n    # reverse y axis\n    scale_y_reverse() + \n    # wrap by image\n    facet_wrap(.~image_type) +\n    # get rid of theme\n    theme_void() +\n    # bigger font size\n    theme(strip.text = element_text(size = 12)))\n}\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-1.png){fig-align='center' width=864}\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-2.png){fig-align='center' width=864}\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-3.png){fig-align='center' width=864}\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-4.png){fig-align='center' width=864}\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-5.png){fig-align='center' width=864}\n:::\n:::\n\n\nWhat do you think? Is 67 PCs enough to reconstruct the data? Since all 191 PCs were used to reconstruct the flags in the middle, we expect it to look identical to the original image as it preserves 100% of the variation. However, using only 67 PCs, or 95% of the variation of the flag images, we see more grainy images with artifacts from other flags. A lot of the reconstructed flags seems to have X's on them along with a symbol from another flag within the dataset. If my goal was to compress these images by reducing the dimensions using PCA, I personally would use more PCs to do so. However, these reconstructed flags might be enough if one were trying to do classification or another machine learning task. So it really depends on what the goal of your project is to determine how many PCs to keep.\n\n\n\n## PCA on the test data\n\nNow let's see how well the PCA on the training data performs on the testing data! To reconstruct the test data, we first use the \"predict\" function in R to obtain the PC scores for the training data using the PCA results from the training data. We can then use the same formula we used for training set to get the reconstructed data for the testing set. Finally, we can plot these flags using ggplot to visualize the reconstructed data.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n### Project testing data ###\n\n# first predict the testing data\ntest_data_projected = predict(pca_result, newdata = test_data)\n\n# Reconstruct the test_data from the projected data using all pcs\nreconstructed_test_data_allpcs = test_data_projected %*% t(pca_result$rotation)\n\n# reconstruct using 95%\nreconstructed_test_data_95 = test_data_projected[,1:pcs_for_95] %*% t(pca_result$rotation[,1:pcs_for_95])\n\n# Create an empty list to store the 250x250x3 matrices\nmatrices_250x250x3 = vector(\"list\", length(length(test_indices)))\n\n# Generate a 250x250x3 matrix for each row in image_matrix\nfor (i in 1:length(test_indices)) {\n  # flattened_image = as.vector(imgs_final[[i]])\n  matrix_250x250x3 = array(reconstructed_test_data_allpcs[i,], dim = c(250, 250, 3))\n  matrices_250x250x3[[i]] = matrix_250x250x3\n}\n\n# Normalize each matrix in the list\nflags_reconstructed_test_data_allpcs = lapply(matrices_250x250x3, normalize_matrix)\n\n\n# now with 95%\n\n\n# Create an empty list to store the 250x250x3 matrices\nmatrices_250x250x3 = vector(\"list\", length(length(test_indices)))\n\n# Generate a 250x250x3 matrix for each row in image_matrix\nfor (i in 1:length(test_indices)) {\n  # flattened_image = as.vector(imgs_final[[i]])\n  matrix_250x250x3 = array(reconstructed_test_data_95[i,], dim = c(250, 250, 3))\n  matrices_250x250x3[[i]] = matrix_250x250x3\n}\n\n# Normalize each matrix in the list\nflags_reconstructed_test_data_95 = lapply(matrices_250x250x3, normalize_matrix)\n\n# for loop getting 5 examples\nfor (i in 1:5) {\n  \n  # getting image - making cimg from imager package and then df\n  img1 = as.data.frame(as.cimg(imgs_final[[test_indices[i]]]), wide = \"c\")  |> \n    # get rgb channels\n    mutate(rgb_value = rgb(c.1, c.2, c.3)) |>\n    # make class for facet_wrap\n    mutate(image_type = \"Original Image\")\n  \n  # getting image - making cimg from imager package and then df\n  img2 = as.data.frame(as.cimg(flags_reconstructed_test_data_allpcs[[i]]), wide = \"c\") |>\n    # get rgb channels\n    mutate(rgb_value = rgb(c.1, c.2, c.3)) |>\n    # make class for facet_wrap\n    mutate(image_type = \"Fully Reconstructed Image\")\n\n  # getting image 1 - making cimg from imager package and then df\n  img3 = as.data.frame(as.cimg(flags_reconstructed_test_data_95[[i]]), wide = \"c\") |>\n    # get rgb channels\n    mutate(rgb_value = rgb(c.1, c.2, c.3)) |>\n    # make class for facet_wrap\n    mutate(image_type = \"67 PCs Reconstructed Image\")\n  \n  # combining to all images\n  all_images = rbind(img1, img2, img3)\n  \n  # make the levels of img variable what i want\n  all_images$image_type = factor(all_images$image_type, levels = c(\"Original Image\", \"Fully Reconstructed Image\",\"67 PCs Reconstructed Image\"))\n\n  # plot image\n  print(ggplot(all_images,aes(y,x))+\n    # getting rgb\n    geom_raster(aes(fill=rgb_value))+\n    # fill image\n    scale_fill_identity() +\n    # reverse y axis\n    scale_y_reverse() + \n    # wrap by image\n    facet_wrap(.~image_type) +\n    # get rid of theme\n    theme_void() +\n    # bigger font size\n    theme(strip.text = element_text(size = 12)))\n}\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-1.png){fig-align='center' width=864}\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-2.png){fig-align='center' width=864}\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-3.png){fig-align='center' width=864}\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-4.png){fig-align='center' width=864}\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-5.png){fig-align='center' width=864}\n:::\n:::\n\n\nNow you can observe that even when using all 191 PCs to reconstruct the test data, the result isn't perfect. However, this makes sense! Since PCA was not performed on the testing data it likely contains new and unseen information for the algorithm. In other words, there exists variation within this new test dataset that was not present in the training dataset. Therefore, achieving a perfectly reconstructed image is not possible.\n\nI would argue that the difference between using 191 PCs or 67 PCs in the test case isn't very significant. Particularly when comparing it to the notable differences in the training dataset, the reconstruction quality doesn't appear to be too bad. There is one interesting observation we can make regarding the last image featuring the trident in the center. It's clear that the reconstructed data was unable to accurately recreate this symbol. Instead, we see a depiction of a star in the middle image and a distinct-ish symbol in the far-right image. This suggests that there likely wasn't a similar symbol present in the training dataset, causing PCA to struggle in reconstructing it.\n\n\n## Visualizing the principal components\n\nTo finish up, lets take a look at the top 10 PCs in image form. To do this, we simply look at the transpose of the *rotation* variable within *pca_results*. We transform this single vector into image form via the same process as before, and visualize using ggplot.\n\n\n<!-- looking at the Principal Components -->\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n### Plot PCs ###\n\n# get pcs\nprincipal_components = t(pca_result$rotation)\n\n# Create an empty list to store the 250x250x3 matrices\nmatrices_250x250x3 = vector(\"list\", dim(principal_components)[1])\n\n# Generate a 250x250x3 matrix for each row in image_matrix\nfor (i in 1:dim(principal_components)[1]) {\n  # flattened_image = as.vector(imgs_final[[i]])\n  matrix_250x250x3 = array(principal_components[i,], dim = c(250, 250, 3))\n  matrices_250x250x3[[i]] = matrix_250x250x3\n}\n\n# Normalize each matrix in the list\nflags_principal_components = lapply(matrices_250x250x3, normalize_matrix)\n\n# want to add all images to this dataframe for ggplot\nall_images = data.frame()\n\n# for loop getting 5 examples\nfor (i in 1:10) {\n  # getting image - making cimg from imager package and then df\n  img = as.data.frame(as.cimg(flags_principal_components[[i]]), wide = \"c\")  |> \n    # get rgb channels\n    mutate(rgb_value = rgb(c.1, c.2, c.3)) |> \n    # make class labels\n    mutate(img_num = paste(\"PC\",i))\n  \n  all_images = rbind(all_images, img)\n  \n  # make the levels of img variable what i want\n  all_images$img_num = factor(all_images$img_num, levels = c(\"PC 1\",\"PC 2\",\"PC 3\",\"PC 4\",\"PC 5\",\n                                                                   \"PC 6\",\"PC 7\",\"PC 8\",\"PC 9\",\"PC 10\"))\n}\n\n# plot image\nprint(ggplot(all_images,aes(y,x))+\n  # getting rgb\n  geom_raster(aes(fill=rgb_value))+\n  # fill image\n  scale_fill_identity() +\n  # facet_wrap\n  facet_wrap(.~ img_num, nrow = 2, ncol = 5) +\n  # reverse y axis\n  scale_y_reverse() + \n  # get rid of theme\n  theme_void() +\n  # bigger font size\n  theme(strip.text = element_text(size = 12)))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-7-1.png){fig-align='center' width=864}\n:::\n:::\n\n\nPersonally, I think this is the coolest part! It's amazing to visually observe the variations captured by each PC. One of the most compelling examples that caught my attention is the comparison between PC6 and PC9. Both PCs capture the flag symbol in the top left corner and exhibit similar colors. However, PC6 splits its colors horizontally, while PC9 splits them vertically. They complement each other in a nice way, showcasing the diverse ways information is reflected across the PCs! Some other PCs, such as PC3 and PC4, have a striking resemblance to specific flag images they were trained on. On the other hand, PCs like PC7 and PC10 seem to combine elements from two or more flags in the dataset, creating cool hybrid representations.\n\n\nThese results actually made me curious about what the appearance of the PCs beyond the top 10 would look like. So let's plot ten of them side by side and compare! This will hopefully provide further insights into the patterns and variations captured by these additional PCs.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n### Plot PCs ###\n\n# want to add all images to this dataframe for ggplot\nall_images = data.frame()\n\n# for loop getting 5 examples\nfor (i in seq(11,191,20)) {\n  # getting image - making cimg from imager package and then df\n  img = as.data.frame(as.cimg(flags_principal_components[[i]]), wide = \"c\")  |> \n    # get rgb channels\n    mutate(rgb_value = rgb(c.1, c.2, c.3)) |> \n    # make class labels\n    mutate(img_num = paste(\"PC\",i))\n  \n  all_images = rbind(all_images, img)\n  \n  # make the levels of img variable what i want\n  all_images$img_num = factor(all_images$img_num, levels = sprintf(\"PC %d\", seq(11, 191, 20)))\n}\n\n# plot image\nprint(ggplot(all_images,aes(y,x))+\n  # getting rgb\n  geom_raster(aes(fill=rgb_value))+\n  # fill image\n  scale_fill_identity() +\n  # facet_wrap\n  facet_wrap(.~ img_num, nrow = 2, ncol = 5) +\n  # reverse y axis\n  scale_y_reverse() + \n  # get rid of theme\n  theme_void() +\n  # bigger font size\n  theme(strip.text = element_text(size = 12)))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-8-1.png){fig-align='center' width=864}\n:::\n:::\n\n\nExcept for PC11, which is only one rank away from the top 10, these PCs exhibit distinct characteristics when compared to the top PCs. Rather than focusing on the overall color of the flag images, they appear to emphasize patterns within the dataset. Interestingly, the final PC essentially corresponds to a completely black image. Checking our *variance_explained* variable, we find it accounts for 7.620894e-35, which is approximately 0% of the dataset highlighting its lack of information. Additionally, many of the later PCs feature specific symbols like stars and shields, which may explain why our reconstructed test data failed to capture the trident but instead exhibited various other symbols such as a star. This serves as an important reminder that predicting new data can be challenging, particularly when it introduces novel variations or, in our case, flag symbols in images that were previously unseen by PCA. This concept holds true across most (if not all) machine learning applications, especially deep learning where the availability of comprehensive training datasets can be a major constraint.\n\n\n\n## Final thoughts\n\nHonestly, this was a really fun project to do! It really helped me understand PCA better and how it can be utilized with images. I also was able to work on my R skills using matrix multiplication, imaging packages, and ggplot! I hope this project will help if you are struggling to understand how to do PCA on images in R. I did some searching and it was hard to find a good resource that went through step-by-step of the process... so hopefully this helped and my code is commented well enough for anyone to understand ðŸ˜Š Let me know if you have any questions about the process or why I did what I did!\n\nThanks for reading ðŸ¥³ðŸ¥³\n\nCaleb ðŸŽ² \n\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}